{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"102mPfXqFZAXMaMbDg-MJDCgo_kIdGODl","timestamp":1711263668581}],"gpuType":"T4","mount_file_id":"102mPfXqFZAXMaMbDg-MJDCgo_kIdGODl","authorship_tag":"ABX9TyPrhnCQYiDliwuTcb0/VOvX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","file = open(\"/content/drive/MyDrive/Introduction to Bioinformatics/Project Proposal/Dataset/histone/H3K4me2.txt\",\"r\")\n","sequences = []\n","class_label = []\n","for line in file:\n","    if '>' in line:\n","        continue\n","    line = line[:-1]\n","    if len(line)>1:\n","        sequences.append(line)\n","    else:\n","        class_label.append(int(line))\n","file.close()\n","removable = []\n","for i in range(len(sequences)):\n","    if len(sequences[i]) < 500:\n","        print(len(sequences[i]))\n","        removable.append(i)\n","\n","iter = 0\n","for x in removable:\n","    sequences.pop(x-iter)\n","    class_label.pop(x-iter)\n","    iter+=1\n","\n","one = 0\n","zero = 0\n","for c in class_label:\n","    if c == 0:\n","        zero+=1\n","    else:\n","        one+=1\n","print(zero, one)\n","print(zero/(zero+one))\n","print(one/(zero+one))\n","class_label = np.array(class_label)\n","\n","from numpy import array\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers.embeddings import Embedding\n","from keras.layers import Dense, Activation, Dropout, SpatialDropout1D, Bidirectional, Flatten\n","from keras.layers.recurrent import LSTM\n","\n","def SeqtoSen(sequences):\n","    sentences = []\n","    for sequence in sequences:\n","        sentence = \"\"\n","        for i in range(len(sequence)-2):\n","            if (len(sentence)>0):\n","                sentence = sentence + \" \";\n","            sentence = sentence + sequence[i:i+3]\n","        sentences.append(sentence)\n","    return sentences\n","\n","\n","import numpy as np\n","\n","vocab_size = 64\n","encoded_docs = [one_hot(sequence, vocab_size) for sequence in sequences]\n","for i in range(len(encoded_docs)):\n","    encoded_docs[i] = np.array(encoded_docs[i])\n","encoded_docs = np.array(encoded_docs)\n","\n","def get_model():\n","    model = Sequential()\n","    model.add(Embedding(input_dim = vocab_size, output_dim = 256, input_length=498))\n","    model.add(SpatialDropout1D(0.2))\n","    model.add(Bidirectional(LSTM(units=256,return_sequences = True)))\n","    model.add(Flatten())\n","    model.add(Dense(128,activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(2, activation='softmax'))\n","    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","    print(model.summary())\n","    return model\n","\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import keras\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef\n","\n","es = EarlyStopping(monitor='val_accuracy',mode='max',verbose=1,patience=200)\n","mc = ModelCheckpoint('best_model.h5',monitor='val_accuracy',mode='max',verbose=1,save_best_only=True, save_weights_only=True)\n","\n","from keras.utils.vis_utils import plot_model\n","model = get_model()\n","plot_model(model,to_file='model.png',show_shapes=True,show_layer_names=True)\n","\n","from sklearn.model_selection import train_test_split\n","X_train_val, X_test, y_train_val, y_test = train_test_split(encoded_docs, class_label, train_size = 0.8, random_state=42, stratify=class_label)\n","train_X, val_X, train_y, val_y = train_test_split(X_train_val, y_train_val, train_size = 0.9, random_state = 42, stratify=y_train_val)\n","model.fit(train_X,train_y, validation_data=(val_X,val_y), epochs=300,batch_size=256,callbacks=[es,mc])\n"],"metadata":{"id":"9gDB0QGxIQ0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_weights('best_model.h5')\n","p = model.predict(X_test)\n","prediction = []\n","for x in p:\n","    if(x[0]>x[1]):\n","        prediction.append(0)\n","    else:\n","        prediction.append(1)\n","\n","f = open(output_file, \"w\")\n","f.write(f'Accuracy: {accuracy_score(y_test,prediction)}\\n')\n","f.write(f'Precision: {precision_score(y_test,prediction)}\\n')\n","f.write(f'Recall: {recall_score(y_test,prediction)}\\n')\n","f.write(f'F1 Score: {f1_score(y_test,prediction)}\\n')\n","f.write(f'MCC Score: {matthews_corrcoef(y_test,prediction)}\\n')\n","f.close()"],"metadata":{"id":"BrF0TnGdRj6-"},"execution_count":null,"outputs":[]}]}